# Humanoid-v5 Reinforcement Learning Project Report

Generated: 2025-12-31 16:22:00

## Project Overview
This project trains and evaluates reinforcement learning algorithms on the Humanoid-v5 environment.

## Directory Structure
- Project Root: `humanoid_rl_project`
- Trained Models: `humanoid_rl_project/models` (1 models)
- Results: `humanoid_rl_project/results` (1 files)
- Videos: `humanoid_rl_project/videos` (0 videos)
- Logs: `humanoid_rl_project/logs`

## Available Models
| Algorithm | Model Path |
|-----------|------------|
| SAC | `models/SAC_20251231_084548/SAC_final.zip` |

## Available Videos
No videos found.

## Environment Information
- **Name**: Humanoid-v5
- **Observation Space**: 376 dimensions
- **Action Space**: 17 dimensions (continuous)
- **Reward Function**: Forward progress + alive bonus - control cost

## Algorithms Implemented
1. **PPO** (Proximal Policy Optimization)
2. **SAC** (Soft Actor-Critic)
3. **TD3** (Twin Delayed DDPG)
4. **DDPG** (Deep Deterministic Policy Gradient)

## How to Use
### 1. Run the Interface
```bash
python humanoid_rl_project.py
```

### 2. Train a Model
Select option 2 from the menu and choose an algorithm.

### 3. Visualize Results
Use options 4-6 to visualize and compare trained models.

### 4. View TensorBoard Logs
```bash
tensorboard --logdir=humanoid_rl_project/logs/
```

## Notes
- Training requires significant computational resources
- Each algorithm trains for 500,000 timesteps by default
- Videos are saved in MP4 format for visualization
- All metrics are saved as JSON files for analysis
